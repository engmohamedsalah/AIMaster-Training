{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUIRRxaCxK8L19CNWSU0Ez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/engmohamedsalah/AIMaster-Training/blob/master/DataPrep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Reading\n",
        "Objective: Implement a function that can detect the type and read data from different file formats such as CSV, Excel, and JSON given the file path only.\n",
        "Tools: Use Pandas for efficient data importing."
      ],
      "metadata": {
        "id": "g3cfzygE8K7t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJkCJhq45mSx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_data(file_path):\n",
        "  \"\"\"\n",
        "  Detects the file format and reads data into a Pandas DataFrame.\n",
        "\n",
        "  Args:\n",
        "    file_path: The path to the file.\n",
        "\n",
        "  Returns:\n",
        "    A Pandas DataFrame containing the data from the file.\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    if file_path.endswith('.csv'):\n",
        "      df = pd.read_csv(file_path)\n",
        "    elif file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
        "      df = pd.read_excel(file_path)\n",
        "    elif file_path.endswith('.json'):\n",
        "      df = pd.read_json(file_path)\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported file format.\")\n",
        "    return df\n",
        "  except Exception as e:\n",
        "    print(f\"Error reading data from file: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Summary\n",
        "Objective: Create a function to print key statistical summaries of the data, including metrics like the average and most frequent values.\n",
        "Tools: Utilize NumPy and Pandas to generate these summaries."
      ],
      "metadata": {
        "id": "CuX1UzNT8xgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def summarize_data(df):\n",
        "  \"\"\"\n",
        "  Prints key statistical summaries of the DataFrame.\n",
        "\n",
        "  Args:\n",
        "    df: The Pandas DataFrame to summarize.\n",
        "  \"\"\"\n",
        "  if df is not None:\n",
        "    print(\"Data Summary:\")\n",
        "    for column in df.columns:\n",
        "      if pd.api.types.is_numeric_dtype(df[column]):\n",
        "        print(f\"\\nColumn: {column}\")\n",
        "        print(f\"  Average: {np.mean(df[column])}\")\n",
        "        print(f\"  Median: {np.median(df[column])}\")\n",
        "        print(f\"  Standard Deviation: {np.std(df[column])}\")\n",
        "      else:\n",
        "        print(f\"\\nColumn: {column}\")\n",
        "        print(f\"  Most Frequent Value: {df[column].mode()[0]}\")\n",
        "        print(f\"  Unique Values: {df[column].nunique()}\")\n"
      ],
      "metadata": {
        "id": "Z1ICCejc80ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling misssing values\n",
        "Objective: Create a function for addressing missing values, offering solutions to either remove or impute them based on set strategies.\n",
        "Tools: Employ methods that ensure data integrity."
      ],
      "metadata": {
        "id": "QdFpiHVs89IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def handle_missing_values(df, strategy='remove'):\n",
        "  \"\"\"\n",
        "  Handles missing values in the DataFrame.\n",
        "\n",
        "  Args:\n",
        "    df: The Pandas DataFrame.\n",
        "    strategy: The strategy for handling missing values, either 'remove' or 'impute'.\n",
        "\n",
        "  Returns:\n",
        "    The DataFrame with missing values handled.\n",
        "  \"\"\"\n",
        "  if df is not None:\n",
        "    if strategy == 'remove':\n",
        "      df = df.dropna()\n",
        "    elif strategy == 'impute':\n",
        "      for column in df.columns:\n",
        "        if pd.api.types.is_numeric_dtype(df[column]):\n",
        "          df[column].fillna(df[column].mean(), inplace=True)\n",
        "        else:\n",
        "          df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "    else:\n",
        "      print(\"Invalid strategy. Choose 'remove' or 'impute'.\")\n",
        "    return df\n",
        "  else:\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "9yR-m0-N9C0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categorical Data encoding\n",
        "Objective: Design functions for encoding categorical data, allowing their conversion into numerical formats for analysis.\n",
        "Tools: Implement encoding techniques effectively."
      ],
      "metadata": {
        "id": "ClQKCai39QUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "def encode_categorical_data(df, method='label'):\n",
        "  \"\"\"\n",
        "  Encodes categorical data in the DataFrame.\n",
        "\n",
        "  Args:\n",
        "    df: The Pandas DataFrame.\n",
        "    method: The encoding method, either 'label' or 'onehot'.\n",
        "\n",
        "  Returns:\n",
        "    The DataFrame with encoded categorical data.\n",
        "  \"\"\"\n",
        "  if df is not None:\n",
        "    if method == 'label':\n",
        "      label_encoder = LabelEncoder()\n",
        "      for column in df.columns:\n",
        "        if pd.api.types.is_string_dtype(df[column]):\n",
        "          df[column] = label_encoder.fit_transform(df[column])\n",
        "    elif method == 'onehot':\n",
        "      onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "      categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "      encoded_data = onehot_encoder.fit_transform(df[categorical_columns])\n",
        "      encoded_df = pd.DataFrame(encoded_data, columns=onehot_encoder.get_feature_names_out(categorical_columns))\n",
        "      df = df.drop(categorical_columns, axis=1)\n",
        "      df = pd.concat([df, encoded_df], axis=1)\n",
        "    else:\n",
        "      print(\"Invalid encoding method. Choose 'label' or 'onehot'.\")\n",
        "    return df\n",
        "  else:\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "cP3YIGle9UzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrapping all function into class"
      ],
      "metadata": {
        "id": "ON_OMscA9tTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def read_data(self, file_path):\n",
        "        \"\"\"\n",
        "        Detects the file format and reads data into a Pandas DataFrame.\n",
        "\n",
        "        Args:\n",
        "          file_path: The path to the file.\n",
        "\n",
        "        Returns:\n",
        "          A Pandas DataFrame containing the data from the file.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            if file_path.endswith('.csv'):\n",
        "                df = pd.read_csv(file_path)\n",
        "            elif file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
        "                df = pd.read_excel(file_path)\n",
        "            elif file_path.endswith('.json'):\n",
        "                df = pd.read_json(file_path)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported file format.\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading data from file: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "    def summarize_data(self, df):\n",
        "        \"\"\"\n",
        "        Prints key statistical summaries of the DataFrame.\n",
        "\n",
        "        Args:\n",
        "          df: The Pandas DataFrame to summarize.\n",
        "        \"\"\"\n",
        "        if df is not None:\n",
        "            print(\"Data Summary:\")\n",
        "            for column in df.columns:\n",
        "                if pd.api.types.is_numeric_dtype(df[column]):\n",
        "                    print(f\"\\nColumn: {column}\")\n",
        "                    print(f\"  Average: {np.mean(df[column])}\")\n",
        "                    print(f\"  Median: {np.median(df[column])}\")\n",
        "                    print(f\"  Standard Deviation: {np.std(df[column])}\")\n",
        "                else:\n",
        "                    print(f\"\\nColumn: {column}\")\n",
        "                    print(f\"  Most Frequent Value: {df[column].mode()[0]}\")\n",
        "                    print(f\"  Unique Values: {df[column].nunique()}\")\n",
        "\n",
        "\n",
        "    def handle_missing_values(self, df, strategy='remove'):\n",
        "        \"\"\"\n",
        "        Handles missing values in the DataFrame.\n",
        "\n",
        "        Args:\n",
        "          df: The Pandas DataFrame.\n",
        "          strategy: The strategy for handling missing values, either 'remove' or 'impute'.\n",
        "\n",
        "        Returns:\n",
        "          The DataFrame with missing values handled.\n",
        "        \"\"\"\n",
        "        if df is not None:\n",
        "            if strategy == 'remove':\n",
        "                df = df.dropna()\n",
        "            elif strategy == 'impute':\n",
        "                for column in df.columns:\n",
        "                    if pd.api.types.is_numeric_dtype(df[column]):\n",
        "                        df[column].fillna(df[column].mean(), inplace=True)\n",
        "                    else:\n",
        "                        df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "            else:\n",
        "                print(\"Invalid strategy. Choose 'remove' or 'impute'.\")\n",
        "            return df\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "    def encode_categorical_data(self, df, method='label'):\n",
        "        \"\"\"\n",
        "        Encodes categorical data in the DataFrame.\n",
        "\n",
        "        Args:\n",
        "          df: The Pandas DataFrame.\n",
        "          method: The encoding method, either 'label' or 'onehot'.\n",
        "\n",
        "        Returns:\n",
        "          The DataFrame with encoded categorical data.\n",
        "        \"\"\"\n",
        "        if df is not None:\n",
        "            if method == 'label':\n",
        "                label_encoder = LabelEncoder()\n",
        "                for column in df.columns:\n",
        "                    if pd.api.types.is_string_dtype(df[column]):\n",
        "                        df[column] = label_encoder.fit_transform(df[column])\n",
        "            elif method == 'onehot':\n",
        "                onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "                categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "                encoded_data = onehot_encoder.fit_transform(df[categorical_columns])\n",
        "                encoded_df = pd.DataFrame(encoded_data, columns=onehot_encoder.get_feature_names_out(categorical_columns))\n",
        "                df = df.drop(categorical_columns, axis=1)\n",
        "                df = pd.concat([df, encoded_df], axis=1)\n",
        "            else:\n",
        "                print(\"Invalid encoding method. Choose 'label' or 'onehot'.\")\n",
        "            return df\n",
        "        else:\n",
        "            return None\n"
      ],
      "metadata": {
        "id": "XNlykEb59m3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Objective: provide example of how to use your class , take object , pass the data and test every function inside it .\n",
        "\n",
        "# Instantiate the DataProcessor class\n",
        "processor = DataProcessor()\n",
        "\n",
        "# Example file path (replace with your actual file path)\n",
        "file_path = 'sample_data/california_housing_train.csv'\n",
        "\n",
        "# Read data from the file\n",
        "df = processor.read_data(file_path)\n",
        "\n",
        "# Print some information about the DataFrame\n",
        "if df is not None:\n",
        "    print(f\"DataFrame shape: {df.shape}\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Summarize the data\n",
        "    processor.summarize_data(df)\n",
        "\n",
        "    # Handle missing values (if any)\n",
        "    df_no_missing = processor.handle_missing_values(df, strategy='impute')\n",
        "\n",
        "    # Encode categorical data (if any)\n",
        "    # Assuming 'ocean_proximity' is a categorical column in your dataset\n",
        "    if 'ocean_proximity' in df_no_missing.columns:\n",
        "        df_encoded = processor.encode_categorical_data(df_no_missing, method='label')\n",
        "        print(\"\\nDataFrame with encoded categorical data:\")\n",
        "        print(df_encoded.head())\n",
        "\n",
        "    else:\n",
        "        print(\"No categorical columns to encode.\")\n"
      ],
      "metadata": {
        "id": "JYue4WHz9zYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WC7n_ba-9hVS"
      }
    }
  ]
}